{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply length tracker\n",
    "This demonstrates the use of a length tracker that, for each conversation in a dataset, attaches a marker to the metadata that indicates which # out of a conversation an utterance is, as well as how far through the conversation this utterance is. This is indexed as a list in the field utterance.meta['length_tracker']. The list consists of [position_of_utterance_in_conversation, percentage_of_conversation']\n",
    "\n",
    "For example, let's imagine a conversation of 100 utterances that begins with Person 1 saying \"Hello, how are you?\" and Person 2  responding with \"Good, thanks. How are you?\"\n",
    "\n",
    "Here is what the metadata would look like:\n",
    "* \"Hello, how are you?\" \n",
    "   * Metadata: [0, 0.0] - This tells us the utterance above is the first utterance in a conversation, and that exactly 0% of the conversation has occurred by the time this utterance is said.\n",
    "* \"Good thanks. How are you?\"\n",
    "  * Metadata: [1, 0.01] - This tells us the utterance above is the 2nd utterance in a conversation, and the exactly 1% of the conversation has occurred at the time this utterance is said.\n",
    "      \n",
    "This transformer allows anyone to easily map information or trends across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules and set up environment\n",
    "import os\n",
    "\n",
    "# replace file path below with your own local convokit\n",
    "os.chdir('/Users/marianneaubin/Documents/Classes/CS6742/Cornell-Conversational-Analysis-Toolkit')\n",
    "import convokit\n",
    "\n",
    "from convokit import Corpus, Parser, LengthTracker, Transformer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open corpus\n",
    "iq2 = convokit.Corpus(filename='datasets/iq2_corpus/iq2_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 471\n",
      "Number of Utterances: 26562\n",
      "Number of Conversations: 108\n"
     ]
    }
   ],
   "source": [
    "# print basic info about the corpus\n",
    "iq2.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = LengthTracker();\n",
    "iq2_length = lt.transform(iq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
