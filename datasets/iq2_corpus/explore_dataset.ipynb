{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dataset\n",
    "## IQ2 Debates\n",
    "*Marianne Aubin Le Quere and Lucas Van Bramer*\n",
    "\n",
    "We are seeking to explore the basic tenets of our dataset. We will later be exploring complexity of language, so we will focus on something that comes quite close to this: word and sentence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get averages\n",
    "First, we want to gather some basic average facts:\n",
    "  * What is the average word length in a debate?\n",
    "  * What is the average sentence length in a debate?\n",
    "  * What is the average utterance length in a debate?\n",
    "  * What is the variability of word, sentence, or utterance length depending on the segment of a debate?\n",
    "  * What is the variability of word, sentence, or utterance length depending on the speaker type of an utterance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules and set up environment\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# replace file path below with your own local convokit\n",
    "os.chdir('/Users/marianneaubin/Documents/Classes/CS6742/Cornell-Conversational-Analysis-Toolkit')\n",
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open created IQ2 corpus\n",
    "corpus = convokit.Corpus(filename='datasets/iq2_corpus/iq2_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 471\n",
      "Number of Utterances: 26562\n",
      "Number of Conversations: 108\n"
     ]
    }
   ],
   "source": [
    "# print basic info about the corpus\n",
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average number of words per utterance is 71.18\n",
      "average number of words per sentence is 14.61\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# for each utterance, calculate how many words and sentences are in the utterance.\n",
    "utter_ids = corpus.get_utterance_ids()\n",
    "word_counts = []\n",
    "sentence_counts = []\n",
    "num_sentences = 0\n",
    "for utt_id in utter_ids:\n",
    "    utt = corpus.get_utterance(utt_id)\n",
    "    \n",
    "    #we simply use spaces to delineate words\n",
    "    words = utt.text.split()\n",
    "    word_count = len(words)\n",
    "    word_counts.append(word_count)\n",
    "    \n",
    "    #we use regex to separate sentences\n",
    "    sentences = re.split(r'[.!?]+', utt.text)\n",
    "    sentences = list(filter(None, sentences))\n",
    "    for sentence in sentences:\n",
    "        words_in_sentence = sentence.split()\n",
    "        words_in_sentence_count = len(words_in_sentence)\n",
    "        sentence_counts.append(words_in_sentence_count)\n",
    "        num_sentences = num_sentences + 1;\n",
    "        \n",
    "# get average word count per utterance\n",
    "word_len_sum = sum(word_counts)\n",
    "utt_num = len(list(corpus.iter_utterances()))\n",
    "avg_word_len = word_len_sum/utt_num\n",
    "print(\"average number of words per utterance is \" + str(round(avg_word_len,2)))\n",
    "\n",
    "# get average word count per sentence\n",
    "word_sent_len_sum = sum(sentence_counts)\n",
    "avg_sentence_len = word_sent_len_sum/num_sentences\n",
    "print(\"average number of words per sentence is \" + str(round(avg_sentence_len, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function get_averages\n",
    "# this function will count the averages of a number of words for a specific scenario\n",
    "#    inputs: list of utterances, instance of corpus\n",
    "#    outputs: average number of words per utterance, average number of words per sentence\n",
    "\n",
    "def get_averages(utt_list, corp): \n",
    "    word_counts = []\n",
    "    sentence_counts = []\n",
    "    letter_counts = []\n",
    "    num_sentences = 0\n",
    "    for utt_id in utt_list:\n",
    "        utt = corp.get_utterance(utt_id)\n",
    "    \n",
    "        #we simply use spaces to delineate words\n",
    "        words = utt.text.split()\n",
    "        word_count = len(words)\n",
    "        word_counts.append(word_count)\n",
    "        \n",
    "        for word in words:\n",
    "            word_length = len(word)\n",
    "            letter_counts.append(word_length)\n",
    "        \n",
    "        #we use regex to separate sentences\n",
    "        sentences = re.split(r'[.!?]+', utt.text)\n",
    "        sentences = list(filter(None, sentences))\n",
    "        for sentence in sentences:\n",
    "            words_in_sentence = sentence.split()\n",
    "            words_in_sentence_count = len(words_in_sentence)\n",
    "            sentence_counts.append(words_in_sentence_count)\n",
    "            num_sentences = num_sentences + 1;\n",
    "        \n",
    "    # get average word count per utterance\n",
    "    word_sum = sum(word_counts)\n",
    "    utt_num = len(utt_list)\n",
    "    avg_word_len = word_sum/utt_num\n",
    "    print(\"average number of words per utterance is \" + str(round(avg_word_len,2)))\n",
    "\n",
    "    # get average word count per sentence\n",
    "    word_sent_len_sum = sum(sentence_counts)\n",
    "    avg_sentence_len = word_sent_len_sum/num_sentences\n",
    "    print(\"average number of words per sentence is \" + str(round(avg_sentence_len, 2)))\n",
    "    \n",
    "    # get average letter count per word\n",
    "    word_len_sum = sum(letter_counts)\n",
    "    avg_word_len = word_len_sum/word_sum\n",
    "    print(\"average number of letters per word is \" + str(round(avg_word_len,2)))\n",
    "    \n",
    "    return avg_word_len, avg_sentence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function get_segment_utterances\n",
    "# this function takes in a whole corpus and will return a list of utterances\n",
    "# only for the segment specified\n",
    "#    inputs: corpus, desired segment\n",
    "#    outputs: list of utterances in a segment\n",
    "\n",
    "def get_segment_utterances(corp, seg):\n",
    "    seg_utter_ids = []\n",
    "    utter_ids = corp.get_utterance_ids()\n",
    "    for utt_id in utter_ids:\n",
    "        segment = corp.get_utterance(utt_id).meta['segment']\n",
    "        if segment == seg:\n",
    "            seg_utter_ids.append(utt_id)\n",
    "    return seg_utter_ids;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall segment stats:\n",
      "average number of words per utterance is 71.18\n",
      "average number of words per sentence is 14.61\n",
      "average number of letters per word is 4.67\n",
      "\n",
      "intro segment stats:\n",
      "average number of words per utterance is 219.26\n",
      "average number of words per sentence is 15.63\n",
      "average number of letters per word is 4.75\n",
      "\n",
      "discussion segment stats:\n",
      "average number of words per utterance is 40.0\n",
      "average number of words per sentence is 13.73\n",
      "average number of letters per word is 4.61\n",
      "\n",
      "conclusion segment stats:\n",
      "average number of words per utterance is 161.29\n",
      "average number of words per sentence is 14.9\n",
      "average number of letters per word is 4.68\n"
     ]
    }
   ],
   "source": [
    "print(\"overall segment stats:\")\n",
    "avg_word_len, avg_sentence_len = get_averages((corpus.get_utterance_ids()), corpus)\n",
    "\n",
    "print(\"\\nintro segment stats:\")\n",
    "#get intro segment id\n",
    "seg_utt_1 = get_segment_utterances(corpus, 0)\n",
    "avg_word_len_1, avg_sentence_len_1 = get_averages(seg_utt_1, corpus)\n",
    "\n",
    "print(\"\\ndiscussion segment stats:\")\n",
    "#get discussion segment id\n",
    "seg_utt_2 = get_segment_utterances(corpus, 1)\n",
    "avg_word_len_2, avg_sentence_len_2 = get_averages(seg_utt_2, corpus)\n",
    "\n",
    "print(\"\\nconclusion segment stats:\")\n",
    "#get conclusion segment id\n",
    "seg_utt_3 = get_segment_utterances(corpus, 2)\n",
    "avg_word_len_3, avg_sentence_len_3 = get_averages(seg_utt_3, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: get_stance\n",
    "# function that will yield whether a given utterance was from a 'for' 'against' or neutral side\n",
    "#    inputs: utterance\n",
    "#    outputs: 0 for neutral, 1 for 'for', -1 for 'against'\n",
    "\n",
    "def get_stance(utterance):\n",
    "        \n",
    "    stance = utterance.user.meta['stance']\n",
    "    \n",
    "    if stance == 'for':\n",
    "        return 1\n",
    "    elif stance == 'against':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: get_winner\n",
    "# function that will yield whether a given utterance was from a winner or from a loser\n",
    "#    inputs: utterance\n",
    "#    outputs: 0 for tie, 1 for winner, -1 for loser, -2 for neutral\n",
    "\n",
    "def get_winner(corp, utterance):\n",
    "    \n",
    "    root = utterance.root\n",
    "    results = corp.conversations[root].meta['results']\n",
    "    \n",
    "    #if delta1 > delta2, the winning side was against\n",
    "    #if delta2 > delta1, the winning side was for\n",
    "    delta1 = int(results['post']['against']) - int(results['pre']['against'])\n",
    "    delta2 = int(results['post']['for']) - int(results['pre']['for'])\n",
    "    \n",
    "    #if the stance of speaker is against\n",
    "    #and against won, return 1\n",
    "    \n",
    "    stance = get_stance(utterance)\n",
    "    \n",
    "    #if stance is neutral, return -2\n",
    "    if stance == 0:\n",
    "        return -2\n",
    "    \n",
    "    #if stance is against, determine if the against side won\n",
    "    if stance == -1:\n",
    "        if delta1 > delta2:\n",
    "            return 1\n",
    "        elif delta2 > delta1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if delta1>delta2:\n",
    "            return -1\n",
    "        elif delta2>delta1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utt_averages(utt_list):\n",
    "    word_counts = []\n",
    "    sentence_counts = []\n",
    "    num_sentences = 0\n",
    "    letter_counts = []\n",
    "    \n",
    "    for utt in utt_list:\n",
    "        \n",
    "        #we simply use spaces to delineate words\n",
    "        words = utt.text.split()\n",
    "        word_count = len(words)\n",
    "        word_counts.append(word_count)\n",
    "        \n",
    "        for word in words:\n",
    "            word_length = len(word)\n",
    "            letter_counts.append(word_length)\n",
    "        \n",
    "        #we use regex to separate sentences\n",
    "        sentences = re.split(r'[.!?]+', utt.text)\n",
    "        sentences = list(filter(None, sentences))\n",
    "        for sentence in sentences:\n",
    "            words_in_sentence = sentence.split()\n",
    "            words_in_sentence_count = len(words_in_sentence)\n",
    "            sentence_counts.append(words_in_sentence_count)\n",
    "            num_sentences = num_sentences + 1;\n",
    "            \n",
    "    # get average word count per utterance\n",
    "    word_sum = sum(word_counts)\n",
    "    utt_num = len(utt_list)\n",
    "    avg_word_len = word_sum/utt_num\n",
    "    print(\"average number of words per utterance is \" + str(round(avg_word_len,2)))\n",
    "\n",
    "    # get average word count per sentence\n",
    "    word_sent_len_sum = sum(sentence_counts)\n",
    "    avg_sentence_len = word_sent_len_sum/num_sentences\n",
    "    print(\"average number of words per sentence is \" + str(round(avg_sentence_len, 2)))\n",
    "    \n",
    "    # get average letter count per word\n",
    "    word_len_sum = sum(letter_counts)\n",
    "    avg_word_len = word_len_sum/word_sum\n",
    "    print(\"average number of letters per word is \" + str(round(avg_word_len,2)))\n",
    "    \n",
    "    return avg_word_len, avg_sentence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6845\n",
      "6641\n",
      "329\n",
      "12747\n",
      "winning stats:\n",
      "average number of words per utterance is 98.72\n",
      "average number of words per sentence is 15.83\n",
      "average number of letters per word is 4.68\n",
      "\n",
      "losing stats\n",
      "average number of words per utterance is 98.28\n",
      "average number of words per sentence is 15.81\n",
      "average number of letters per word is 4.68\n",
      "\n",
      "tied stats\n",
      "average number of words per utterance is 129.98\n",
      "average number of words per sentence is 18.19\n",
      "average number of letters per word is 4.66\n",
      "\n",
      "neutral stats\n",
      "average number of words per utterance is 40.76\n",
      "average number of words per sentence is 12.08\n",
      "average number of letters per word is 4.66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.655070466452887, 12.078504974207812)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we try and see if there is a correlation between winning utterances and losing utterances\n",
    "# we also include neutral stances for completion\n",
    "\n",
    "winning_utts = []\n",
    "losing_utts = []\n",
    "tied_utts = []\n",
    "neutral_utts = []\n",
    "\n",
    "#iterate through each utterance\n",
    "for utt in corpus.utterances:\n",
    "    \n",
    "    utterance = corpus.get_utterance(utt)\n",
    "    if (get_winner(corpus, utterance) == 1):\n",
    "        winning_utts.append(utterance)\n",
    "    elif get_winner(corpus, utterance) == 0:\n",
    "        tied_utts.append(utterance)\n",
    "    elif get_winner(corpus, utterance) == -1:\n",
    "        losing_utts.append(utterance)\n",
    "    else:\n",
    "        neutral_utts.append(utterance)\n",
    "        \n",
    "print(len(winning_utts))\n",
    "print(len(losing_utts))\n",
    "print(len(tied_utts))\n",
    "print(len(neutral_utts))\n",
    "\n",
    "print(\"winning stats:\")\n",
    "get_utt_averages(winning_utts)\n",
    "\n",
    "print(\"\\nlosing stats\")\n",
    "get_utt_averages(losing_utts)\n",
    "\n",
    "print(\"\\ntied stats\")\n",
    "get_utt_averages(tied_utts)\n",
    "\n",
    "print(\"\\nneutral stats\")\n",
    "get_utt_averages(neutral_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
